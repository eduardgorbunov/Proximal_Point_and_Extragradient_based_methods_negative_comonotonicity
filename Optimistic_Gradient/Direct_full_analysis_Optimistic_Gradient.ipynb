{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444a698f-c801-46cc-a213-ef5f66bceabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If PEPit is not installed yet, you can run this cell.\n",
    "!pip install pepit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c69a5ff7-42fe-4973-8a88-65bc5c820a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code before executing the cell below\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "from PEPit import PEP\n",
    "from PEPit.function import Function\n",
    "\n",
    "\n",
    "class LipschitzNegativeComonotoneOperator(Function):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 rho,\n",
    "                 L=1.,\n",
    "                 is_leaf=True,\n",
    "                 decomposition_dict=None,\n",
    "                 reuse_gradient=True):\n",
    "        \n",
    "        super().__init__(is_leaf=is_leaf,\n",
    "                         decomposition_dict=decomposition_dict,\n",
    "                         reuse_gradient=True)\n",
    "        # Store L and rho\n",
    "        self.rho = rho\n",
    "        self.L = L\n",
    "\n",
    "        if self.L == np.inf:\n",
    "            print(\"\\033[96m(PEPit) The class of Lipschitz negative comonotone operators is necessarily continuous.\\n\"\n",
    "                  \"To instantiate an operator, please avoid using the class LipschitzNegativeComonotoneOperator with\\n\"\n",
    "                  \" L == np.inf. Instead, please use the class NegativeComonotoneOperator (which accounts for the fact\\n\"\n",
    "                  \"that the image of the operator at certain points might not be a singleton).\\033[0m\")\n",
    "\n",
    "    def add_class_constraints(self):\n",
    "        for point_i in self.list_of_points:\n",
    "\n",
    "            xi, gi, fi = point_i\n",
    "\n",
    "            for point_j in self.list_of_points:\n",
    "\n",
    "                xj, gj, fj = point_j\n",
    "\n",
    "                if (xi != xj) | (gi != gj):\n",
    "                    # Interpolation conditions of negative comonotone operator class\n",
    "                    self.add_constraint((gi - gj) * (xi - xj) + self.rho * (gi - gj)**2 >= 0)\n",
    "                    # Interpolation conditions of Lipschitz operator class\n",
    "                    self.add_constraint((gi - gj)**2 - self.L**2 * (xi - xj)**2 <= 0)\n",
    "\n",
    "class LipschitzStarNegativeComonotoneOperator(Function):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 rho,\n",
    "                 L=1.,\n",
    "                 is_leaf=True,\n",
    "                 decomposition_dict=None,\n",
    "                 reuse_gradient=True):\n",
    "        \n",
    "        super().__init__(is_leaf=is_leaf,\n",
    "                         decomposition_dict=decomposition_dict,\n",
    "                         reuse_gradient=True)\n",
    "        # Store L and rho\n",
    "        self.rho = rho\n",
    "        self.L = L\n",
    "\n",
    "        if self.L == np.inf:\n",
    "            print(\"\\033[96m(PEPit) The class of Lipschitz star negative comonotone operators is necessarily continuous.\\n\"\n",
    "                  \"To instantiate an operator, please avoid using the class LipschitzNegativeComonotoneOperator with\\n\"\n",
    "                  \" L == np.inf. Instead, please use the class NegativeComonotoneOperator (which accounts for the fact\\n\"\n",
    "                  \"that the image of the operator at certain points might not be a singleton).\\033[0m\")\n",
    "\n",
    "    def add_class_constraints(self):\n",
    "        for point_i in self.list_of_points:\n",
    "\n",
    "            xi, gi, fi = point_i\n",
    "\n",
    "            for point_j in self.list_of_points:\n",
    "\n",
    "                xj, gj, fj = point_j\n",
    "\n",
    "                if (xi != xj) | (gi != gj):\n",
    "                    # Interpolation conditions of Lipschitz operator class\n",
    "                    self.add_constraint((gi - gj)**2 - self.L**2 * (xi - xj)**2 <= 0)\n",
    "                    \n",
    "        for point_i in self.list_of_stationary_points:\n",
    "\n",
    "            xi, gi, fi = point_i\n",
    "\n",
    "            for point_j in self.list_of_points:\n",
    "\n",
    "                xj, gj, fj = point_j\n",
    "\n",
    "                if point_i != point_j:\n",
    "                    # Interpolation conditions of star negative comonotone operator class\n",
    "                    self.add_constraint(gj * (xj-xi) + self.rho *  gj ** 2 >= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985f3a88-932d-4687-b5e2-fd01083dca2d",
   "metadata": {},
   "source": [
    "## $\\rho$-star negative comonotone and Lipschitz operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70313191-5d82-440d-87b0-cd7d34f14e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wc_optimisticgradient_star(n, gamma1, gamma2, L, rho, verbose=1):\n",
    "\n",
    "    # Instantiate PEP\n",
    "    problem = PEP()\n",
    "\n",
    "    # Declare an indicator function and a monotone operator\n",
    "    F = problem.declare_function(LipschitzStarNegativeComonotoneOperator, rho=rho, L=L)\n",
    "\n",
    "\n",
    "    # Start by defining its unique optimal point xs = x_*\n",
    "    xs = F.stationary_point()\n",
    "\n",
    "    # Then define the starting point x0 of the algorithm and its gradient value g0\n",
    "    x0 = problem.set_initial_point()\n",
    "\n",
    "    # Set the initial constraint that is the distance between x0 and x^*\n",
    "    problem.set_initial_condition((x0 - xs) ** 2 <= 1)\n",
    "\n",
    "    # Compute n steps of the optimistic gradient method starting from x0\n",
    "    x = x0\n",
    "    xtilde = x\n",
    "    V = F.gradient(x)\n",
    "    obj = V**2\n",
    "    for _ in range(n):\n",
    "        xtilde = x - gamma1 * V\n",
    "        V = F.gradient(xtilde)\n",
    "        x = x - gamma2 * V\n",
    "        obj = obj + F.gradient(x)**2\n",
    "\n",
    "    # Set the performance metric\n",
    "    problem.set_performance_metric(obj/(n+1))\n",
    "\n",
    "    # Solve the PEP\n",
    "    pepit_verbose = max(verbose, 0)\n",
    "    pepit_tau = problem.solve(verbose=pepit_verbose)\n",
    "\n",
    "    # Compute theoretical guarantee (for comparison)\n",
    "    theoretical_tau = 1/(gamma1*gamma2*(1-L**2*(gamma1+gamma2)**2)*(n+1))\n",
    "\n",
    "    # Print conclusion if required\n",
    "    if verbose != -1:\n",
    "        print('*** Example file: worst-case performance of the optimistic gradient method ***')\n",
    "        print('\\tPEPit guarantee:\\t 1/(n+1) \\sum(k=0 to n) ||F(x(k))||^2 <= {:.6} ||x0 - xs||^2'.format(pepit_tau))\n",
    "        print('\\tTheorem 4.2:\\t 1/(n+1) \\sum(k=0 to n) ||F(x(k))||^2 <= {:.6} ||x0 - xs||^2'.format(theoretical_tau))\n",
    "\n",
    "    # Return the worst-case guarantee of the evaluated method ( and the reference theoretical value)\n",
    "    return pepit_tau, theoretical_tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1cae4d1-b467-4308-88d3-98dca5461925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PEPit) Setting up the problem: size of the main PSD matrix: 63x63\n",
      "(PEPit) Setting up the problem: performance measure is minimum of 1 element(s)\n",
      "(PEPit) Setting up the problem: initial conditions and general constraints (1 constraint(s) added)\n",
      "(PEPit) Setting up the problem: interpolation conditions for 1 function(s)\n",
      "\t\t function 1 : 3843 constraint(s) added\n",
      "(PEPit) Setting up the problem: 0 lmi constraint(s) added\n",
      "(PEPit) Compiling SDP\n",
      "(PEPit) Calling SDP solver\n",
      "(PEPit) Solver status: optimal (solver: MOSEK); optimal value: 0.3788572332601821\n",
      "\u001b[96m(PEPit) Postprocessing: solver's output is not entirely feasible (smallest eigenvalue of the Gram matrix is: -4.9e-09 < 0).\n",
      " Small deviation from 0 may simply be due to numerical error. Big ones should be deeply investigated.\n",
      " In any case, from now the provided values of parameters are based on the projection of the Gram matrix onto the cone of symmetric semi-definite matrix.\u001b[0m\n",
      "*** Example file: worst-case performance of the optimistic gradient method ***\n",
      "\tPEPit guarantee:\t 1/(n+1) \\sum(k=0 to n) ||F(x(k))||^2 <= 0.378857 ||x0 - xs||^2\n",
      "\tTheorem 4.2:\t 1/(n+1) \\sum(k=0 to n) ||F(x(k))||^2 <= 0.632511 ||x0 - xs||^2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3788572332601821, 0.6325110689437065)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 30\n",
    "\n",
    "\n",
    "L = 1\n",
    "rho = .1              # should satisfy 0<= rho < 1/2/L\n",
    "gamma1 = 1/2          # should satisfy 2*rho < gamma1 < 1/L\n",
    "gamma2 = .2           # should satisfy 0 < gamma2 <= min(1/L-gamma1, gamma1-2*rho)\n",
    "\n",
    "wc_optimisticgradient_star(n, gamma1, gamma2, L, rho, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a38ff72-ce55-48d6-89d9-c98b86e3a46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8db2401-29c8-4b05-a1e4-010b13f4e152",
   "metadata": {},
   "source": [
    "## $\\rho$-negative comonotone and Lipschitz operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07ea94af-2586-4583-9946-1308b3557755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wc_optimisticgradient(n, gamma, L, rho, verbose=1):\n",
    "\n",
    "    # Instantiate PEP\n",
    "    problem = PEP()\n",
    "\n",
    "    # Declare an indicator function and a monotone operator\n",
    "    F = problem.declare_function(LipschitzNegativeComonotoneOperator, rho=rho, L=L)\n",
    "\n",
    "\n",
    "    # Start by defining its unique optimal point xs = x_*\n",
    "    xs = F.stationary_point()\n",
    "\n",
    "    # Then define the starting point x0 of the algorithm and its gradient value g0\n",
    "    x0 = problem.set_initial_point()\n",
    "\n",
    "    # Set the initial constraint that is the distance between x0 and x^*\n",
    "    problem.set_initial_condition((x0 - xs) ** 2 <= 1)\n",
    "\n",
    "    # Compute n steps of the optimistic gradient method starting from x0\n",
    "    x = x0\n",
    "    xtilde = x\n",
    "    V = F.gradient(x)\n",
    "    obj = V**2\n",
    "    for _ in range(n):\n",
    "        xtilde = x - gamma * V\n",
    "        V = F.gradient(xtilde)\n",
    "        x = x - gamma * V\n",
    "\n",
    "    # Set the performance metric\n",
    "    obj = F.gradient(x)**2\n",
    "    problem.set_performance_metric(obj)\n",
    "\n",
    "    # Solve the PEP\n",
    "    pepit_verbose = max(verbose, 0)\n",
    "    pepit_tau = problem.solve(verbose=pepit_verbose)\n",
    "\n",
    "    # Compute theoretical guarantee (for comparison)\n",
    "    theoretical_tau = 717/(n*gamma*(gamma-3*rho)+800*gamma**2)\n",
    "\n",
    "    # Print conclusion if required\n",
    "    if verbose != -1:\n",
    "        print('*** Example file: worst-case performance of the optimistic gradient method ***')\n",
    "        print('\\tPEPit guarantee:\\t ||F(x(n))||^2 <= {:.6} ||x0 - xs||^2'.format(pepit_tau))\n",
    "        print('\\tTheorem 4.2:\\t ||F(x(n))||^2 <= {:.6} ||x0 - xs||^2'.format(theoretical_tau))\n",
    "\n",
    "    # Return the worst-case guarantee of the evaluated method ( and the reference theoretical value)\n",
    "    return pepit_tau, theoretical_tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04ad8ae5-efed-4456-9f4c-a8ca9936e0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PEPit) Setting up the problem: size of the main PSD matrix: 14x14\n",
      "(PEPit) Setting up the problem: performance measure is minimum of 1 element(s)\n",
      "(PEPit) Setting up the problem: initial conditions and general constraints (1 constraint(s) added)\n",
      "(PEPit) Setting up the problem: interpolation conditions for 1 function(s)\n",
      "\t\t function 1 : 312 constraint(s) added\n",
      "(PEPit) Setting up the problem: 0 lmi constraint(s) added\n",
      "(PEPit) Compiling SDP\n",
      "(PEPit) Calling SDP solver\n",
      "(PEPit) Solver status: optimal (solver: MOSEK); optimal value: 0.4733421380779232\n",
      "\u001b[96m(PEPit) Postprocessing: solver's output is not entirely feasible (smallest eigenvalue of the Gram matrix is: -2.33e-09 < 0).\n",
      " Small deviation from 0 may simply be due to numerical error. Big ones should be deeply investigated.\n",
      " In any case, from now the provided values of parameters are based on the projection of the Gram matrix onto the cone of symmetric semi-definite matrix.\u001b[0m\n",
      "*** Example file: worst-case performance of the optimistic gradient method ***\n",
      "\tPEPit guarantee:\t ||F(x(n))||^2 <= 0.473342 ||x0 - xs||^2\n",
      "\tTheorem 4.2:\t ||F(x(n))||^2 <= 8.55575 ||x0 - xs||^2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4733421380779232, 8.555745948966289)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "\n",
    "\n",
    "L = 1\n",
    "rho = .05             # should satisfy 0<= rho < 5/62/L\n",
    "gamma = 10/31/L       # should satisfy 4*rho <= gamma <= 10/31/L\n",
    "\n",
    "wc_optimisticgradient(n, gamma, L, rho, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e265e4-03f8-44cc-9a1f-3b3665ddfaa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
